Search.setIndex({"docnames": ["deployment/vllm", "getting_started/installation", "getting_started/quickstart", "index", "inference/chat", "quantization/awq", "quantization/gguf", "quantization/gptq", "run_locally/llama.cpp", "run_locally/ollama", "training/SFT/example", "training/SFT/index", "web_ui/text_generation_webui"], "filenames": ["deployment/vllm.rst", "getting_started/installation.rst", "getting_started/quickstart.rst", "index.rst", "inference/chat.rst", "quantization/awq.rst", "quantization/gguf.rst", "quantization/gptq.rst", "run_locally/llama.cpp.rst", "run_locally/ollama.rst", "training/SFT/example.rst", "training/SFT/index.rst", "web_ui/text_generation_webui.rst"], "titles": ["vLLM", "Installation", "Quickstart", "Welcome to Qwen!", "Using Transformers to Chat", "AWQ", "GGUF", "Quantization with GPTQ", "llama.cpp", "Ollama", "Supervised Finetuning Example", "SFT", "Text Generation Web UI"], "terms": {"we": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12], "recommend": [0, 5, 10], "you": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12], "try": [0, 2, 4], "http": [0, 2, 5, 7, 8, 12], "github": [3, 5, 7, 8, 12], "com": [5, 7, 8, 12], "project": [], "__": [], "your": [0, 2, 4, 10, 12], "deploy": [0, 5], "qwen": [0, 2, 4, 5, 6, 7, 9, 10, 12], "It": [0, 5, 7, 8, 9, 12], "i": [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12], "simpl": [0, 2, 5, 7, 10], "us": [0, 1, 2, 3, 5, 6, 7, 9, 10, 12], "fast": [0, 2], "state": 0, "art": 0, "throughtput": 0, "efficienct": 0, "manag": 0, "attent": [0, 10], "kei": [0, 2, 5, 7, 10], "valu": [0, 10], "memori": [0, 5, 8], "pagedattent": 0, "continu": [0, 4], "input": [0, 2, 4], "request": 0, "optim": [0, 10], "cuda": [0, 2, 4, 5, 7], "kernel": 0, "etc": [0, 3, 12], "To": [0, 1, 2, 5, 6, 7, 8, 10], "learn": [0, 10], "more": [0, 2, 3, 4, 6, 8, 9, 10, 12], "about": [0, 2, 5, 6, 7, 10], "pleas": [0, 3, 6, 8, 12], "refer": [0, 4, 5, 6, 8, 12], "paper": 0, "document": [0, 2, 4, 5, 6, 7, 8], "By": [0, 4, 10], "default": [0, 4, 9, 10], "can": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 12], "pip": [0, 2, 5, 7, 8, 10, 12], "0": [0, 1, 2, 3, 4, 5, 7, 9, 10], "3": [0, 1, 2, 6, 8, 12], "ar": [0, 2, 3, 4, 5, 7, 8, 9, 10, 12], "11": [0, 12], "8": [0, 1, 6, 7, 8, 9], "check": [0, 2, 10], "note": [0, 4, 7, 10], "offici": [0, 5, 7, 8, 9], "link": 0, "some": [0, 8, 10], "help": [0, 2, 4, 5, 6, 7, 9, 10], "also": [0, 4, 5, 6, 7, 8, 9, 10], "advis": [0, 1, 2, 5, 7, 8, 10, 12], "rai": 0, "distribut": [0, 10], "support": [0, 3, 5, 7, 8, 10, 12], "qwen2": 0, "code": [0, 2, 4, 5, 7, 10], "e": [0, 5, 6, 7, 10, 12], "g": [0, 5, 6, 7, 10, 12], "qwen1": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 12], "5": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 12], "The": [0, 2, 3, 4, 5, 6, 7, 9, 10, 12], "simplest": [0, 4, 6, 10, 12], "usag": [0, 2, 8, 9, 12], "demonstr": [0, 2, 5, 6, 7, 8, 10], "below": [0, 2, 4, 5, 6, 7, 9, 10, 12], "from": [0, 1, 2, 4, 5, 7, 9, 10], "import": [0, 2, 4, 5, 7, 10], "llm": [0, 2, 5, 6, 7, 8, 9], "samplingparam": 0, "pass": [0, 8, 10], "decod": [0, 2, 4], "hyperparamet": [0, 5, 7, 8, 10], "7b": [0, 2, 3, 4, 5, 6, 7, 8, 9, 12], "chat": [0, 2, 3, 5, 6, 7, 8, 9, 10, 12], "max_token": 0, "maximum": [0, 2, 4, 8, 10], "length": [0, 2, 3, 4, 10], "gener": [0, 2, 3, 4, 5, 6, 7, 8, 10], "sampling_param": 0, "temperatur": [0, 9], "7": [0, 9], "top_p": [0, 9], "repetition_penalti": 0, "1": [0, 3, 8, 9], "05": [0, 9, 10], "512": [0, 2, 4, 5, 7, 8], "name": [0, 5, 6, 7, 8, 10], "path": [0, 5, 6, 7, 10], "gptq": [0, 3, 10, 12], "awq": [0, 3, 10], "prepar": [0, 5, 7, 8, 12], "prompt": [0, 2, 4, 5, 7, 8, 9], "tell": [0, 2, 5, 7, 10], "me": [0, 2, 4, 5, 7, 10], "someth": [0, 2, 5, 7, 10], "larg": [0, 2, 3, 4, 5, 7, 10], "languag": [0, 2, 3, 4, 5, 7, 10], "messag": [0, 2, 4, 5, 7, 9, 10], "role": [0, 2, 3, 4, 5, 7, 10, 12], "system": [0, 2, 4, 5, 7, 9, 10], "content": [0, 2, 4, 5, 7, 9, 10], "assist": [0, 2, 4, 5, 7, 9, 10], "user": [0, 2, 4, 5, 7, 9, 10], "text": [0, 2, 3, 4, 5, 7, 10], "token": [0, 2, 4, 5, 6, 7, 8, 10], "apply_chat_templ": [0, 2, 4, 5, 7, 10], "fals": [0, 2, 4, 5, 7, 8, 10], "add_generation_prompt": [0, 2, 4, 5, 7], "true": [0, 2, 4, 5, 6, 7], "output": [0, 2, 4, 6, 8, 10], "print": [0, 2, 4, 5, 7], "generated_text": [0, 4], "f": [0, 8, 9, 10], "r": [0, 12], "easi": [0, 2, 5, 10], "build": [0, 2, 4, 5, 6, 7, 10], "an": [0, 2, 4, 5, 6, 8, 10, 12], "which": [0, 4, 5, 6, 7, 8, 10], "deploi": [0, 2], "server": [0, 2, 5, 7, 12], "implement": [0, 5, 8], "protocol": 0, "start": [0, 1, 2, 4, 6, 10], "localhost": [0, 2, 5, 7, 12], "8000": [0, 2, 5, 7], "specifi": [0, 4, 5, 7, 10], "address": 0, "host": 0, "port": 0, "argument": [0, 4, 6, 10], "run": [0, 2, 5, 6, 7, 10, 12], "command": [0, 6, 8, 9, 10], "shown": [0, 2, 4, 5, 6, 7, 9, 12], "python": [0, 1, 2, 5, 6, 7, 12], "m": [0, 2, 5, 7, 8, 10], "entrypoint": [0, 2, 5, 7], "api_serv": [0, 2, 5, 7], "don": [0, 9], "t": [0, 9], "need": [0, 2, 4, 5, 6, 7, 8, 9, 10, 12], "worri": [0, 10], "templat": [0, 4, 5, 7, 9, 10], "provid": [0, 2, 4, 5, 6, 7, 8, 10, 12], "Then": [0, 2, 5, 6, 7, 8, 9, 10, 12], "creat": [0, 2, 5, 6, 7, 8, 9, 12], "interfac": [0, 2, 12], "commun": [0, 2, 3, 6], "curl": [0, 2, 5, 7], "v1": [0, 2, 5, 7, 8], "complet": [0, 2, 5, 7], "h": [0, 2, 5, 7, 8], "type": [0, 2, 5, 7, 10, 12], "applic": [0, 2, 4, 5, 7], "json": [0, 2, 5, 7, 10, 12], "d": [0, 2, 5, 7, 10], "client": [0, 2, 5, 7], "packag": [0, 2, 5, 7, 10, 12], "set": [0, 2, 4, 5, 7, 9, 10], "": [0, 2, 5, 7], "base": [0, 2, 3, 5, 6, 7, 10, 12], "openai_api_kei": [0, 2, 5, 7], "empti": [0, 2, 5, 7], "openai_api_bas": [0, 2, 5, 7], "api_kei": [0, 2, 5, 7], "base_url": [0, 2, 5, 7], "chat_respons": [0, 2, 5, 7], "respons": [0, 2, 4, 5, 7, 9], "scale": [0, 3], "up": [0, 2, 5, 7, 10], "throughput": 0, "leverag": 0, "devic": [0, 2, 4, 5, 7, 9], "besid": [0, 4], "like": [0, 6, 7, 8, 10, 12], "72b": [0, 3, 9], "imposs": 0, "singl": [0, 10], "here": [0, 2, 4, 6, 8, 10, 12], "how": [0, 2, 4, 5, 7, 8, 12], "tensor": [0, 7], "parallel": 0, "just": [0, 2, 4, 5, 6, 7, 9, 12], "tensor_parallel_s": 0, "4": [0, 1, 2, 5, 6, 7, 8], "size": [0, 3, 7, 9, 10], "differ": [0, 6, 9, 10, 12], "includ": [0, 3, 10, 12], "squeezellm": 0, "show": [0, 2, 4, 5, 7], "almost": 0, "same": [0, 5, 7], "abov": [0, 2, 4, 6, 10], "except": [0, 7, 9, 10], "addit": 0, "For": [0, 3, 5, 6, 7, 8, 9, 10, 12], "exampl": [0, 2, 3, 4, 5, 6, 7, 8, 11, 12], "int8": [0, 7], "int4": [0, 7], "similarli": 0, "ad": [0, 10], "addition": [0, 10], "combin": 0, "kv": 0, "cach": 0, "fp8": 0, "e5m2": 0, "kv_cache_dtyp": 0, "fp8_e5m2": 0, "dtype": [0, 7], "mai": [0, 7], "encount": 0, "oom": 0, "issu": [0, 2], "pretti": 0, "annoi": 0, "two": [0, 10], "make": [0, 2, 10], "fix": 0, "first": [0, 2, 5, 6, 7, 8, 9, 12], "one": [0, 5, 6, 7, 9, 10], "max": [0, 10], "len": [0, 2, 4, 5, 7], "our": [0, 3, 4, 5, 7, 8, 10], "max_postiion_embed": 0, "32768": 0, "thu": 0, "thi": [0, 2, 4, 5, 6, 7, 8, 10, 12], "lead": 0, "higher": [0, 1, 9], "requir": [0, 5, 6, 10, 12], "reduc": [0, 5, 8], "proper": 0, "yourself": 0, "often": 0, "anoth": [0, 10], "pai": [0, 10], "util": [0, 10], "9": 0, "level": [0, 6, 7], "tackl": [0, 2, 10], "problem": [0, 10], "why": 0, "find": [0, 8, 9], "alwai": 0, "take": [0, 2, 10, 12], "so": [0, 7], "much": [0, 10], "get": [1, 2, 4, 8], "quick": [1, 2], "transform": [1, 3, 10, 12], "librari": [1, 4, 8, 10], "hug": [1, 3, 8, 10], "face": [1, 3, 8, 10], "model": [1, 2, 3, 4, 8, 9, 10, 12], "collect": [1, 3], "latest": [1, 3, 5, 7], "least": 1, "version": [1, 3, 5, 7], "37": [1, 2], "forg": 1, "adivs": [], "pytorch": 1, "2": [1, 6, 8], "guid": 2, "quickli": [2, 10], "well": [2, 6, 10], "infer": [2, 4, 7, 8], "sure": [2, 6, 10], "have": [2, 5, 6, 7, 8, 9, 10], "instal": [2, 3, 5, 6, 7, 8, 9, 12], "follow": [2, 3, 4, 5, 6, 7, 8, 10], "veri": [2, 5, 7, 10], "snippet": [2, 5, 7], "automodelforcausallm": [2, 4, 5, 7, 10], "autotoken": [2, 4, 5, 7, 10], "load": [2, 4, 5, 7, 10], "onto": [2, 4, 5, 7], "now": [2, 3, 4, 5, 6, 7, 9, 10], "do": [2, 4, 5, 7, 8, 12], "add": [2, 4, 6], "trust_remote_cod": [2, 4], "from_pretrain": [2, 4, 5, 7, 10], "torch_dtyp": [2, 4], "auto": [2, 4, 5, 7], "device_map": [2, 4, 5, 7], "instead": [2, 4], "directli": [2, 4, 5, 6, 7, 10, 12], "But": [2, 4], "format": [2, 4, 5, 6, 7, 8, 10], "give": [2, 4, 5, 7], "short": [2, 4, 5, 7], "introduct": [2, 4, 5, 7, 10], "model_input": [2, 4, 5, 7], "return_tensor": [2, 4, 5, 7], "pt": [2, 4, 5, 7], "max_new_token": [2, 4, 5, 7], "control": [2, 4], "generated_id": [2, 4, 5, 7], "input_id": [2, 4, 5, 7], "output_id": [2, 4, 5, 7], "zip": [2, 4, 5, 7, 8], "batch_decod": [2, 4, 5, 7], "skip_special_token": [2, 4, 5, 7], "previous": 2, "see": [2, 3], "modeling_qwen": 2, "py": [2, 6, 12], "previou": [2, 4], "inform": [2, 3, 6, 7, 8], "practic": [2, 4, 12], "download": [2, 8, 9], "chang": [2, 10], "line": [2, 4, 5, 7, 10], "stream": 2, "mode": 2, "textstream": [2, 4], "reus": 2, "befor": [2, 4, 6, 10], "last": 2, "streamer": [2, 4], "texstream": [2, 4], "skip_prompt": [2, 4], "framework": 2, "serv": 2, "In": [2, 4, 5, 6, 7, 10, 12], "openai": [2, 5, 7], "api": [2, 5, 7], "compat": [2, 5, 7], "servic": [2, 12], "fun": [2, 8], "would": [2, 6], "love": 2, "know": 2, "its": 2, "feel": 2, "free": 2, "other": [2, 8, 10], "multimod": 3, "seri": [3, 8, 10], "team": 3, "alibaba": 3, "group": 3, "moel": 3, "upgrad": 3, "both": [3, 7], "pretrain": 3, "multilingu": 3, "data": [3, 5, 6, 7], "post": 3, "qualiti": [3, 6], "align": [3, 10], "human": [3, 10], "prefer": [3, 10], "capabl": [3, 10], "natur": [3, 10], "understand": [3, 4, 10], "vision": 3, "audio": 3, "tool": 3, "plai": [3, 8, 12], "ai": 3, "agent": 3, "ha": [3, 5, 7, 8, 10, 12], "featur": [3, 10], "6": [3, 6, 8], "5b": [3, 9], "8b": [3, 9], "4b": [3, 9], "14b": [3, 9], "each": [3, 5, 7, 10], "stabl": [3, 12], "32k": 3, "context": 3, "all": [3, 6, 10], "rag": 3, "visit": [3, 6, 9], "blog": 3, "modelscop": 3, "join": 3, "discord": 3, "wechat": 3, "look": 3, "forward": [3, 10], "quickstart": 3, "llama": [3, 6, 10, 12], "cpp": [3, 6, 12], "ollama": 3, "gguf": [3, 12], "vllm": 3, "sft": [3, 10], "supervis": [3, 11], "finetun": [3, 5, 7, 11], "most": [4, 10], "signific": [4, 10], "either": [4, 10], "write": [4, 10], "sever": 4, "essenti": [4, 8], "method": [4, 6, 7, 8, 10], "perform": [4, 6, 8, 10, 12], "origin": 4, "repo": [4, 8, 10, 12], "replac": [4, 6], "function": [4, 10], "convert": [4, 6], "im_start": [4, 9], "n": [4, 8, 10, 12], "notabl": 4, "appli": [4, 6, 10, 12], "chatml": [4, 5, 7, 10], "term": 4, "dialog": 4, "histori": 4, "With": 4, "modifi": [4, 10], "repeat": 4, "textiteratorstream": 4, "store": [4, 10], "readi": 4, "queue": 4, "downstream": 4, "iter": 4, "thread": 4, "generation_kwarg": 4, "dict": [4, 7], "target": [4, 10], "kwarg": 4, "new_text": 4, "read": 4, "figur": [4, 8, 12], "out": [4, 8, 12], "advanc": [4, 12], "activ": [5, 12], "awar": 5, "weight": [5, 7, 10], "hardwar": 5, "friendli": 5, "approach": 5, "low": [5, 6], "bit": [5, 6, 7, 8], "onli": [5, 6, 9], "speed": [5, 7], "3x": 5, "compar": 5, "fp16": [5, 6, 10], "algorithm": 5, "mean": [5, 7], "those": [5, 7, 10], "train": [5, 7, 10, 12], "actual": [5, 7], "basic": [5, 7], "launch": [5, 7, 12], "If": [5, 7, 8, 10], "want": [5, 6, 7, 8, 9, 10], "suggest": [5, 7], "sourc": [5, 7, 10], "git": [5, 7, 8, 12], "clone": [5, 7, 8, 12], "casper": 5, "hansen": 5, "cd": [5, 7, 8, 12], "suppos": [5, 6, 7, 9], "dataset": [5, 7, 8, 10], "alpaca": [5, 7, 10], "calibr": [5, 6, 7], "autoawqforcausallm": 5, "model_path": [5, 7, 10], "your_model_path": [5, 7], "quant_path": [5, 6, 7], "your_quantized_model_path": [5, 7], "quant_config": [5, 6], "zero_point": 5, "q_group_siz": 5, "128": [5, 7], "w_bit": 5, "gemm": 5, "safetensor": [5, 7, 12], "calibar": [5, 7], "what": [5, 7, 8, 10], "put": [5, 6, 7, 12], "sampl": [5, 7, 10], "list": [5, 7, 10], "As": [5, 7], "msg": [5, 7], "c": [5, 7, 8], "append": [5, 7], "strip": 5, "where": [5, 6, 7, 8, 9, 10, 12], "typic": [5, 6, 7], "who": [5, 7], "am": [5, 7], "process": [5, 7, 10], "calib_data": 5, "final": [5, 7], "save": [5, 6, 7, 10], "save_quant": [5, 7], "shard_siz": 5, "4gb": 5, "save_pretrain": [5, 6, 7], "obtain": 5, "enjoi": [5, 7, 10, 12], "recent": 6, "local": [6, 8, 9, 12], "popular": [6, 12], "without": [6, 8, 10], "better": 6, "imatrix": 6, "wai": [6, 10, 12], "move": 6, "instruct": 6, "guidanc": [6, 10], "NOT": 6, "hf": [6, 10], "outfil": 6, "qwen1_5": [6, 8, 9], "directori": [6, 8, 12], "second": [6, 7, 8], "under": 6, "rememb": 6, "q4_0": [6, 8, 9], "until": 6, "finish": [6, 9, 12], "improv": 6, "possibl": 6, "solut": 6, "script": [6, 12], "when": 6, "autoawq": [6, 12], "export_compat": 6, "save_quantz": 6, "usual": [6, 12], "q2_k": 6, "q3_k_m": 6, "q4_k_m": 6, "q5_0": 6, "q5_k_m": [6, 8], "q6_k": 6, "q8_0": 6, "gpt": [7, 8], "shot": 7, "approxim": 7, "order": 7, "auto_gptq": 7, "autogptqforcausallm": 7, "basequantizeconfig": 7, "quantize_config": 7, "group_siz": 7, "damp_perc": 7, "01": 7, "desc_act": 7, "significantli": 7, "perplex": 7, "slightli": 7, "bad": 7, "static_group": 7, "sym": 7, "true_sequenti": 7, "model_name_or_path": 7, "none": [7, 10], "model_file_base_nam": 7, "max_len": 7, "8192": [7, 10], "torch": [7, 12], "int": [7, 10], "attention_mask": 7, "ne": 7, "pad_token_id": 7, "log": 7, "basicconfig": 7, "asctim": 7, "levelnam": 7, "info": 7, "datefmt": 7, "y": 7, "cache_examples_on_gpu": 7, "use_safetensor": 7, "unfortun": 7, "doe": 7, "shard": 7, "everyth": 7, "mimim": 8, "setup": 8, "enabl": [8, 10], "machin": 8, "plain": 8, "depend": [8, 12], "avx": 8, "avx2": 8, "avx512": 8, "x86": 8, "architectur": 8, "quantiz": [8, 12], "faster": 8, "footprint": 8, "cpu": 8, "gpu": [8, 10], "hybrid": 8, "partial": 8, "acceler": [8, 10], "larger": 8, "than": 8, "total": [8, 10], "vram": 8, "capac": 8, "unifi": 8, "linux": [8, 9], "maco": [8, 9, 12], "step": [8, 9], "enter": [8, 12], "ggerganov": 8, "organ": [8, 10], "search": [8, 9], "huggingfac": 8, "cli": 8, "huggingface_hub": 8, "model_repo": 8, "gguf_fil": 8, "dir": 8, "local_dir": 8, "symlink": 8, "main": 8, "color": 8, "cml": 8, "txt": [8, 12], "number": [8, 10], "There": [8, 10, 12], "choos": [8, 9, 10], "them": [8, 10, 12], "introduc": [8, 9, 10, 12], "u": 8, "sai": 8, "wiki": 8, "test": 8, "wget": 8, "s3": 8, "amazonaw": 8, "research": 8, "metamind": 8, "io": 8, "wikitext": 8, "raw": 8, "ref": 8, "salesforc": 8, "o": [8, 12], "unzip": 8, "ggml": 8, "calcul": 8, "over": 8, "655": 8, "chunk": 8, "24": 8, "43": 8, "per": [8, 10], "eta": 8, "45": 8, "hour": 8, "5970": 8, "1807": 8, "0382": 8, "wait": 8, "time": [8, 10], "still": [8, 10], "difficult": 8, "platform": 8, "alreadi": 8, "been": 8, "part": 8, "few": 9, "avail": 9, "window": 9, "next": 9, "detail": [9, 10], "websit": 9, "click": 9, "sometim": 9, "pull": 9, "own": 9, "call": 9, "modelfil": 9, "creativ": 9, "lower": 9, "coher": 9, "paramet": [9, 10], "repeat_penalti": 9, "top_k": 9, "20": 9, "im_end": 9, "end": 9, "qwen7b": 9, "onc": 9, "revis": 10, "fastchat": 10, "trainer": 10, "multi": 10, "full": 10, "tune": 10, "lora": [10, 12], "q": 10, "peft": 10, "deepspe": 10, "optimum": 10, "jsonl": 10, "file": [10, 12], "dictionari": 10, "corpu": 10, "thei": 10, "varieti": 10, "task": 10, "unknown": 10, "my": 10, "self": 10, "made": 10, "object": 10, "field": 10, "while": 10, "option": 10, "label": 10, "open": 10, "herm": 10, "ani": 10, "string": 10, "w": 10, "dump": 10, "bash": 10, "script_path": 10, "data_path": 10, "config_path": 10, "sh": [10, 12], "qlora": 10, "configur": 10, "dive": 10, "section": [10, 12], "core": 10, "correspond": 10, "brief": 10, "insid": [10, 12], "environ": [10, 12], "variabl": 10, "gpus_per_nod": 10, "nnode": 10, "node_rank": 10, "master_addr": 10, "master_port": 10, "No": 10, "too": 10, "respect": 10, "zero2": 10, "zero3": 10, "case": 10, "bf16": 10, "precis": 10, "mix": 10, "output_dir": 10, "adapt": 10, "num_train_epoch": 10, "epoch": 10, "gradient_accumulation_step": 10, "gradient": 10, "accumul": 10, "per_device_train_batch_s": 10, "batch": 10, "equalt": 10, "number_of_gpu": 10, "learning_r": 10, "rate": 10, "warmup_step": 10, "warmup": 10, "lr_scheduler_typ": 10, "schedul": 10, "weight_decai": 10, "decai": 10, "adam_beta2": 10, "beta_2": 10, "adam": 10, "model_max_length": 10, "sequenc": 10, "use_lora": 10, "whether": 10, "q_lora": 10, "gradient_checkpoint": 10, "checkpoint": 10, "mainli": 10, "dataclass": 10, "class": 10, "trainingargu": 10, "cache_dir": 10, "str": 10, "adamw_torch": 10, "metadata": 10, "right": 10, "pad": 10, "possibli": 10, "truncat": 10, "bool": 10, "loraargu": 10, "lora_r": 10, "64": 10, "lora_alpha": 10, "16": 10, "lora_dropout": 10, "float": 10, "lora_target_modul": 10, "default_factori": 10, "lambda": 10, "q_proj": 10, "k_proj": 10, "v_proj": 10, "o_proj": 10, "up_proj": 10, "gate_proj": 10, "down_proj": 10, "lora_weight_path": 10, "lora_bia": 10, "allow": 10, "specif": 10, "determin": 10, "rank": 10, "alpha": 10, "dropout": 10, "modul": 10, "linear": 10, "layer": 10, "bia": 10, "bitsandbyt": [10, 12], "safe_save_model_for_hf_train": 10, "get_peft_state_maybe_zero_3": 10, "preprocess": 10, "tokenizer_config": [10, 12], "make_supervised_data_modul": 10, "superviseddataset": 10, "lazysuperviseddataset": 10, "initi": 10, "loraconfig": 10, "should": [10, 12], "prepare_model_for_kbit_train": 10, "leav": 10, "effort": 10, "cup": 10, "coffe": 10, "abl": 10, "altern": [10, 12], "axolotl": 10, "factori": 10, "after": [10, 12], "consid": 10, "rlhf": 10, "stai": 10, "tutori": 10, "tgw": 12, "oobabooga": 12, "similar": 12, "automatic1111": 12, "diffus": 12, "webui": 12, "multipl": 12, "backend": 12, "through": 12, "exllamav2": 12, "autogptq": 12, "ctransform": 12, "quip": 12, "shell": 12, "start_linux": 12, "start_window": 12, "bat": 12, "start_maco": 12, "start_wsl": 12, "manual": 12, "conda": 12, "textgen": 12, "torchvis": 12, "torchaudio": 12, "requirements_apple_silicon": 12, "howev": 12, "temporarili": 12, "unsatisfactori": 12, "folder": 12, "config": 12, "generation_config": 12, "00001": 12, "00004": 12, "00002": 12, "00003": 12, "index": 12, "merg": 12, "vocab": 12, "brows": 12, "7860": 12, "__theme": 12, "dark": 12, "lot": 12, "even": 12, "incorpor": 12, "extens": 12, "whisper": 12, "go": 12}, "objects": {}, "objtypes": {}, "objnames": {}, "titleterms": {"vllm": [0, 2, 5, 7], "instal": [0, 1, 10], "offlin": 0, "batch": 0, "infer": [0, 3], "openai": 0, "api": 0, "compat": 0, "servic": 0, "multi": 0, "gpu": 0, "distributr": 0, "serv": 0, "quantiz": [0, 3, 5, 6, 7], "model": [0, 5, 6, 7], "troubleshoot": 0, "pip": 1, "conda": 1, "quickstart": [2, 9, 10, 12], "hug": 2, "face": 2, "transform": [2, 4, 5, 7], "modelscop": 2, "deploy": [2, 3], "next": [2, 4, 10, 12], "step": [2, 4, 10, 12], "welcom": 3, "qwen": [3, 8], "document": 3, "get": 3, "start": 3, "run": [3, 8, 9], "local": 3, "web": [3, 12], "ui": [3, 12], "train": 3, "us": [4, 8], "chat": 4, "basic": 4, "usag": [4, 5, 7, 10], "stream": 4, "mode": 4, "awq": [5, 6], "your": [5, 6, 7, 8, 9], "own": [5, 7], "autoawq": 5, "gguf": [6, 8, 9], "make": [6, 8], "file": [6, 8, 9], "With": 6, "scale": 6, "gptq": 7, "autogptq": 7, "llama": 8, "cpp": 8, "prerequisit": 8, "perplex": 8, "evalu": 8, "lm": 8, "studio": 8, "ollama": 9, "supervis": 10, "finetun": 10, "exampl": 10, "data": 10, "prepar": 10, "advanc": 10, "shell": 10, "script": 10, "python": 10, "sft": 11, "text": 12, "gener": 12}, "envversion": {"sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.viewcode": 1, "sphinx.ext.intersphinx": 1, "sphinx": 60}, "alltitles": {"Next Step": [[4, "next-step"], [10, "next-step"], [12, "next-step"], [2, "next-step"]], "Using Transformers to Chat": [[4, "using-transformers-to-chat"]], "Basic Usage": [[4, "basic-usage"]], "Streaming Mode": [[4, "streaming-mode"]], "AWQ": [[5, "awq"]], "Usage of AWQ Quantized Models with Transformers": [[5, "usage-of-awq-quantized-models-with-transformers"]], "Usage of AWQ Quantized Models with vLLM": [[5, "usage-of-awq-quantized-models-with-vllm"]], "Quantize Your Own Model with AutoAWQ": [[5, "quantize-your-own-model-with-autoawq"]], "GGUF": [[6, "gguf"]], "Quantize Your Models and Make GGUF Files": [[6, "quantize-your-models-and-make-gguf-files"]], "Quantize Your Models With AWQ Scales": [[6, "quantize-your-models-with-awq-scales"]], "Quantization with GPTQ": [[7, "quantization-with-gptq"]], "Usage of GPTQ Models with Transformers": [[7, "usage-of-gptq-models-with-transformers"]], "Usage of GPTQ Quantized Models with vLLM": [[7, "usage-of-gptq-quantized-models-with-vllm"]], "Quantize Your Own Model with AutoGPTQ": [[7, "quantize-your-own-model-with-autogptq"]], "llama.cpp": [[8, "llama-cpp"]], "Prerequisites": [[8, "prerequisites"]], "Running Qwen GGUF Files": [[8, "running-qwen-gguf-files"]], "Make Your GGUF Files": [[8, "make-your-gguf-files"]], "Perplexity Evaluation": [[8, "perplexity-evaluation"]], "Use GGUF with LM Studio": [[8, "use-gguf-with-lm-studio"]], "Quickstart": [[9, "quickstart"], [10, "quickstart"], [12, "quickstart"], [2, "quickstart"]], "Ollama": [[9, "ollama"]], "Run Ollama with Your GGUF Files": [[9, "run-ollama-with-your-gguf-files"]], "Installation": [[10, "installation"], [0, "installation"], [1, "installation"]], "Supervised Finetuning Example": [[10, "supervised-finetuning-example"]], "Data Preparation": [[10, "data-preparation"]], "Advanced Usages": [[10, "advanced-usages"]], "Shell Scripts": [[10, "shell-scripts"]], "Python Script": [[10, "python-script"]], "SFT": [[11, "sft"]], "Text Generation Web UI": [[12, "text-generation-web-ui"]], "vLLM": [[0, "vllm"]], "Offline Batched Inference": [[0, "offline-batched-inference"]], "OpenAI-API Compatible API Service": [[0, "openai-api-compatible-api-service"]], "Multi-GPU Distributred Serving": [[0, "multi-gpu-distributred-serving"]], "Serving Quantized Models": [[0, "serving-quantized-models"]], "Troubleshooting": [[0, "troubleshooting"]], "Install with Pip": [[1, "install-with-pip"]], "Install with Conda": [[1, "install-with-conda"]], "Hugging Face Transformers & ModelScope": [[2, "hugging-face-transformers-modelscope"]], "vLLM for Deployment": [[2, "vllm-for-deployment"]], "Welcome to Qwen!": [[3, "welcome-to-qwen"]], "Documentation": [[3, "documentation"]], "Getting Started": [[3, null]], "Inference": [[3, null]], "Run Locally": [[3, null]], "Web UI": [[3, null]], "Quantization": [[3, null]], "Deployment": [[3, null]], "Training": [[3, null]]}, "indexentries": {}})